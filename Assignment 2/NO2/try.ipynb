{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c32814b",
   "metadata": {},
   "source": [
    "# Association Rule Mining for Cassava Yield Data - Fertilizer Patterns Across Seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb997c",
   "metadata": {},
   "source": [
    "##### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c10cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2c816",
   "metadata": {},
   "source": [
    "##### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198c7d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/openpyxl/packaging/core.py:99: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/openpyxl/packaging/core.py:99: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "# Loading the particular data sheet needed\n",
    "df = pd.read_excel('Cassava_Yield_Data.xlsx', sheet_name='Cassava Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d14df",
   "metadata": {},
   "source": [
    "##### Display basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74327a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sesn</th>\n",
       "      <th>locn</th>\n",
       "      <th>block</th>\n",
       "      <th>rep</th>\n",
       "      <th>tillage</th>\n",
       "      <th>ferT</th>\n",
       "      <th>Plants_harvested</th>\n",
       "      <th>No_bigtubers</th>\n",
       "      <th>Weigh_bigtubers</th>\n",
       "      <th>No_mediumtubers</th>\n",
       "      <th>Weight_mediumtubers</th>\n",
       "      <th>No_smalltubers</th>\n",
       "      <th>Weight_smalltubers</th>\n",
       "      <th>Totaltuberno</th>\n",
       "      <th>AV_tubers_Plant</th>\n",
       "      <th>Total_tubweight</th>\n",
       "      <th>plotsize</th>\n",
       "      <th>HEC</th>\n",
       "      <th>TotalWeightperhectare</th>\n",
       "      <th>TotalTuberperHectare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conv</td>\n",
       "      <td>F2150</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>2.5</td>\n",
       "      <td>319</td>\n",
       "      <td>4.7</td>\n",
       "      <td>380</td>\n",
       "      <td>13.571429</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>10000</td>\n",
       "      <td>13584.905660</td>\n",
       "      <td>716981.132075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conv</td>\n",
       "      <td>F1100</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110</td>\n",
       "      <td>4.6</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>370</td>\n",
       "      <td>13.214286</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>10000</td>\n",
       "      <td>16226.415094</td>\n",
       "      <td>698113.207547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conv</td>\n",
       "      <td>F3200</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>115</td>\n",
       "      <td>5.2</td>\n",
       "      <td>319</td>\n",
       "      <td>4.4</td>\n",
       "      <td>436</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>10000</td>\n",
       "      <td>18490.566038</td>\n",
       "      <td>822641.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conv</td>\n",
       "      <td>F5300</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>60</td>\n",
       "      <td>2.7</td>\n",
       "      <td>303</td>\n",
       "      <td>4.8</td>\n",
       "      <td>369</td>\n",
       "      <td>13.178571</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>10000</td>\n",
       "      <td>15471.698113</td>\n",
       "      <td>696226.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conv</td>\n",
       "      <td>F4250</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>82</td>\n",
       "      <td>3.4</td>\n",
       "      <td>332</td>\n",
       "      <td>4.7</td>\n",
       "      <td>417</td>\n",
       "      <td>14.892857</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>10000</td>\n",
       "      <td>15849.056604</td>\n",
       "      <td>786792.452830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sesn  locn  block  rep tillage    ferT  Plants_harvested  No_bigtubers  \\\n",
       "0     2     1      1    1     conv  F2150                28             0   \n",
       "1     2     1      1    1     conv  F1100                28             0   \n",
       "2     2     1      1    1     conv  F3200                28             2   \n",
       "3     2     1      1    1     conv  F5300                28             6   \n",
       "4     2     1      1    1     conv  F4250                28             3   \n",
       "\n",
       "   Weigh_bigtubers  No_mediumtubers  Weight_mediumtubers  No_smalltubers  \\\n",
       "0              0.0               61                  2.5             319   \n",
       "1              0.0              110                  4.6             260   \n",
       "2              0.2              115                  5.2             319   \n",
       "3              0.7               60                  2.7             303   \n",
       "4              0.3               82                  3.4             332   \n",
       "\n",
       "   Weight_smalltubers  Totaltuberno  AV_tubers_Plant  Total_tubweight  \\\n",
       "0                 4.7           380        13.571429              7.2   \n",
       "1                 4.0           370        13.214286              8.6   \n",
       "2                 4.4           436        15.571429              9.8   \n",
       "3                 4.8           369        13.178571              8.2   \n",
       "4                 4.7           417        14.892857              8.4   \n",
       "\n",
       "   plotsize    HEC  TotalWeightperhectare  TotalTuberperHectare  \n",
       "0       5.3  10000           13584.905660         716981.132075  \n",
       "1       5.3  10000           16226.415094         698113.207547  \n",
       "2       5.3  10000           18490.566038         822641.509434  \n",
       "3       5.3  10000           15471.698113         696226.415094  \n",
       "4       5.3  10000           15849.056604         786792.452830  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"First few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30610ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (115, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2850bd",
   "metadata": {},
   "source": [
    "The dataset has 20 columns and 115 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd1daa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sesn                     0\n",
       "locn                     0\n",
       "block                    0\n",
       "rep                      0\n",
       "tillage                  0\n",
       "ferT                     0\n",
       "Plants_harvested         0\n",
       "No_bigtubers             0\n",
       "Weigh_bigtubers          0\n",
       "No_mediumtubers          0\n",
       "Weight_mediumtubers      0\n",
       "No_smalltubers           0\n",
       "Weight_smalltubers       0\n",
       "Totaltuberno             0\n",
       "AV_tubers_Plant          0\n",
       "Total_tubweight          0\n",
       "plotsize                 0\n",
       "HEC                      0\n",
       "TotalWeightperhectare    0\n",
       "TotalTuberperHectare     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486e4df",
   "metadata": {},
   "source": [
    "The dataset has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2708f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sesn</th>\n",
       "      <th>locn</th>\n",
       "      <th>block</th>\n",
       "      <th>rep</th>\n",
       "      <th>Plants_harvested</th>\n",
       "      <th>No_bigtubers</th>\n",
       "      <th>Weigh_bigtubers</th>\n",
       "      <th>No_mediumtubers</th>\n",
       "      <th>Weight_mediumtubers</th>\n",
       "      <th>No_smalltubers</th>\n",
       "      <th>Weight_smalltubers</th>\n",
       "      <th>Totaltuberno</th>\n",
       "      <th>AV_tubers_Plant</th>\n",
       "      <th>Total_tubweight</th>\n",
       "      <th>plotsize</th>\n",
       "      <th>HEC</th>\n",
       "      <th>TotalWeightperhectare</th>\n",
       "      <th>TotalTuberperHectare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.0</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.521739</td>\n",
       "      <td>1.521739</td>\n",
       "      <td>2.043478</td>\n",
       "      <td>2.043478</td>\n",
       "      <td>18.565217</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.614783</td>\n",
       "      <td>49.521739</td>\n",
       "      <td>2.771304</td>\n",
       "      <td>146.252174</td>\n",
       "      <td>2.511304</td>\n",
       "      <td>199.773913</td>\n",
       "      <td>10.525355</td>\n",
       "      <td>5.897391</td>\n",
       "      <td>4.486957</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13094.339623</td>\n",
       "      <td>431822.336810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.501713</td>\n",
       "      <td>0.501713</td>\n",
       "      <td>0.809931</td>\n",
       "      <td>0.809931</td>\n",
       "      <td>6.442908</td>\n",
       "      <td>7.367544</td>\n",
       "      <td>1.174678</td>\n",
       "      <td>29.920757</td>\n",
       "      <td>1.774911</td>\n",
       "      <td>87.351663</td>\n",
       "      <td>1.303354</td>\n",
       "      <td>102.555168</td>\n",
       "      <td>3.248495</td>\n",
       "      <td>3.040702</td>\n",
       "      <td>0.485134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6896.716668</td>\n",
       "      <td>184839.313619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2380.952381</td>\n",
       "      <td>135714.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>115.500000</td>\n",
       "      <td>8.027778</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8095.238095</td>\n",
       "      <td>275000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>11904.761905</td>\n",
       "      <td>419047.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>3.950000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>273.500000</td>\n",
       "      <td>12.973684</td>\n",
       "      <td>8.150000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>16421.832884</td>\n",
       "      <td>589285.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>33571.428571</td>\n",
       "      <td>835849.056604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sesn        locn       block         rep  Plants_harvested  \\\n",
       "count  115.000000  115.000000  115.000000  115.000000        115.000000   \n",
       "mean     1.521739    1.521739    2.043478    2.043478         18.565217   \n",
       "std      0.501713    0.501713    0.809931    0.809931          6.442908   \n",
       "min      1.000000    1.000000    1.000000    1.000000          5.000000   \n",
       "25%      1.000000    1.000000    1.000000    1.000000         14.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000         18.000000   \n",
       "75%      2.000000    2.000000    3.000000    3.000000         28.000000   \n",
       "max      2.000000    2.000000    3.000000    3.000000         28.000000   \n",
       "\n",
       "       No_bigtubers  Weigh_bigtubers  No_mediumtubers  Weight_mediumtubers  \\\n",
       "count    115.000000       115.000000       115.000000           115.000000   \n",
       "mean       4.000000         0.614783        49.521739             2.771304   \n",
       "std        7.367544         1.174678        29.920757             1.774911   \n",
       "min        0.000000         0.000000         0.000000             0.000000   \n",
       "25%        0.000000         0.000000        26.500000             1.300000   \n",
       "50%        0.000000         0.000000        44.000000             2.500000   \n",
       "75%        5.500000         0.700000        65.500000             3.950000   \n",
       "max       41.000000         7.000000       126.000000             8.100000   \n",
       "\n",
       "       No_smalltubers  Weight_smalltubers  Totaltuberno  AV_tubers_Plant  \\\n",
       "count      115.000000          115.000000    115.000000       115.000000   \n",
       "mean       146.252174            2.511304    199.773913        10.525355   \n",
       "std         87.351663            1.303354    102.555168         3.248495   \n",
       "min         37.000000            0.500000     57.000000         3.800000   \n",
       "25%         84.000000            1.500000    115.500000         8.027778   \n",
       "50%        109.000000            2.100000    179.000000        10.666667   \n",
       "75%        221.000000            3.600000    273.500000        12.973684   \n",
       "max        376.000000            5.400000    443.000000        19.200000   \n",
       "\n",
       "       Total_tubweight    plotsize      HEC  TotalWeightperhectare  \\\n",
       "count       115.000000  115.000000    115.0             115.000000   \n",
       "mean          5.897391    4.486957  10000.0           13094.339623   \n",
       "std           3.040702    0.485134      0.0            6896.716668   \n",
       "min           1.000000    4.200000  10000.0            2380.952381   \n",
       "25%           3.400000    4.200000  10000.0            8095.238095   \n",
       "50%           6.000000    4.200000  10000.0           11904.761905   \n",
       "75%           8.150000    5.300000  10000.0           16421.832884   \n",
       "max          14.100000    5.300000  10000.0           33571.428571   \n",
       "\n",
       "       TotalTuberperHectare  \n",
       "count            115.000000  \n",
       "mean          431822.336810  \n",
       "std           184839.313619  \n",
       "min           135714.285714  \n",
       "25%           275000.000000  \n",
       "50%           419047.619048  \n",
       "75%           589285.714286  \n",
       "max           835849.056604  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdf2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Sesn', 'locn', 'block', 'rep', 'tillage ', 'ferT', 'Plants_harvested', 'No_bigtubers', 'Weigh_bigtubers', 'No_mediumtubers', 'Weight_mediumtubers', 'No_smalltubers', 'Weight_smalltubers', 'Totaltuberno', 'AV_tubers_Plant', 'Total_tubweight', 'plotsize', 'HEC', 'TotalWeightperhectare', 'TotalTuberperHectare']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0527fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique seasons: [2 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique seasons:\", df['Sesn'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a88417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique fertilizers: ['F2150' 'F1100' 'F3200' 'F5300' 'F4250']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique fertilizers:\", df['ferT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f24848",
   "metadata": {},
   "source": [
    "There are only 5 types of the fertizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8c81ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique locations: [1 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique locations:\", df['locn'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b46d55",
   "metadata": {},
   "source": [
    "There are only 2 locations; 1 - Soroti and 2 - Mukono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2700b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by season, location, tillage and collect fertilizers\n",
    "transactions = df.groupby(['Sesn', 'locn', 'block'])['ferT'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9cf3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare transaction data for Apriori\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions['ferT']).transform(transactions['ferT'])\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7398078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ef45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlxtend/frequent_patterns/association_rules.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  cert_metric = np.where(certainty_denom == 0, 0, certainty_num / certainty_denom)\n"
     ]
    }
   ],
   "source": [
    "# Generate rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0263d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rules where antecedents and consequents are fertilizers (not other attributes)\n",
    "rules = rules[rules['consequents'].apply(lambda x: len(x) == 1 and 'F' in str(list(x)[0]))]\n",
    "rules = rules[rules['antecedents'].apply(lambda x: len(x) == 1 and 'F' in str(list(x)[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae28db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  support  confidence  lift\n",
      "0      (F2150)     (F1100)      1.0         1.0   1.0\n",
      "1      (F1100)     (F2150)      1.0         1.0   1.0\n",
      "2      (F3200)     (F1100)      1.0         1.0   1.0\n",
      "3      (F1100)     (F3200)      1.0         1.0   1.0\n",
      "4      (F4250)     (F1100)      1.0         1.0   1.0\n",
      "5      (F1100)     (F4250)      1.0         1.0   1.0\n",
      "6      (F1100)     (F5300)      1.0         1.0   1.0\n",
      "7      (F5300)     (F1100)      1.0         1.0   1.0\n",
      "8      (F3200)     (F2150)      1.0         1.0   1.0\n",
      "9      (F2150)     (F3200)      1.0         1.0   1.0\n",
      "10     (F4250)     (F2150)      1.0         1.0   1.0\n",
      "11     (F2150)     (F4250)      1.0         1.0   1.0\n",
      "12     (F2150)     (F5300)      1.0         1.0   1.0\n",
      "13     (F5300)     (F2150)      1.0         1.0   1.0\n",
      "14     (F3200)     (F4250)      1.0         1.0   1.0\n",
      "15     (F4250)     (F3200)      1.0         1.0   1.0\n",
      "16     (F3200)     (F5300)      1.0         1.0   1.0\n",
      "17     (F5300)     (F3200)      1.0         1.0   1.0\n",
      "18     (F4250)     (F5300)      1.0         1.0   1.0\n",
      "19     (F5300)     (F4250)      1.0         1.0   1.0\n"
     ]
    }
   ],
   "source": [
    "# Display\n",
    "print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba09056e",
   "metadata": {},
   "source": [
    "### Data preprocessing for association rule mining\n",
    "#### We'll create transactions where each transaction represents a season-location-block combination and the items are the fertilizers used in that context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique identifier for each experimental context (season-location-block)\n",
    "df['context_id'] = df['Sesn'].astype(str) + '_' + df['locn'].astype(str) + '_' + df['block'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739644da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by context and collect all fertilizers used in that context\n",
    "context_fertilizers = df.groupby('context_id')['ferT'].apply(list).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique contexts:\", len(context_fertilizers))\n",
    "print(\"\\nSample context-fertilizer combinations:\")\n",
    "print(context_fertilizers.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e96925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for association rule mining\n",
    "transactions = context_fertilizers['ferT'].tolist()\n",
    "\n",
    "print(\"Sample transactions:\")\n",
    "for i, transaction in enumerate(transactions[:12]):\n",
    "    print(f\"Transaction {i+1}: {transaction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transactions to binary matrix format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "transactions_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTransaction matrix (first 10 rows):\")\n",
    "transactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTransaction matrix shape: {transactions_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequent itemsets using Apriori algorithm\n",
    "frequent_itemsets = apriori(transactions_df, min_support=0.1, use_colnames=True)\n",
    "frequent_itemsets = frequent_itemsets.sort_values('support', ascending=False)\n",
    "\n",
    "print(\"Frequent itemsets (min_support=0.1):\")\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the support of frequent itemsets\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_itemsets = frequent_itemsets.head(15).copy()\n",
    "top_itemsets['itemset_str'] = top_itemsets['itemsets'].apply(lambda x: ', '.join(list(x)))\n",
    "plt.barh(top_itemsets['itemset_str'], top_itemsets['support'])\n",
    "plt.xlabel('Support')\n",
    "plt.title('Top Frequent Fertilizer Itemsets')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "rules = rules.sort_values('confidence', ascending=False)\n",
    "\n",
    "print(\"Association Rules (min_confidence=0.5):\")\n",
    "print(f\"Number of rules generated: {len(rules)}\")\n",
    "print(\"\\nTop association rules:\")\n",
    "display(rules.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rules with high lift (meaningful associations)\n",
    "high_lift_rules = rules[rules['lift'] > 1.2]\n",
    "print(f\"\\nRules with lift > 1.2: {len(high_lift_rules)}\")\n",
    "\n",
    "if len(high_lift_rules) > 0:\n",
    "    display(high_lift_rules.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf16c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze associations specifically across seasons\n",
    "# Create transactions grouped by season and location\n",
    "df['season_loc'] = df['Sesn'].astype(str) + '_' + df['locn'].astype(str)\n",
    "season_fertilizers = df.groupby('season_loc')['ferT'].apply(list).reset_index()\n",
    "\n",
    "season_transactions = season_fertilizers['ferT'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to binary matrix\n",
    "te_season = TransactionEncoder()\n",
    "te_ary_season = te_season.fit(season_transactions).transform(season_transactions)\n",
    "season_transactions_df = pd.DataFrame(te_ary_season, columns=te_season.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a457e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate frequent itemsets for season-based analysis\n",
    "frequent_itemsets_season = apriori(season_transactions_df, min_support=0.3, use_colnames=True)\n",
    "frequent_itemsets_season = frequent_itemsets_season.sort_values('support', ascending=False)\n",
    "\n",
    "print(\"Season-based frequent itemsets:\")\n",
    "print(frequent_itemsets_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dfe174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate association rules for season-based analysis\n",
    "season_rules = association_rules(frequent_itemsets_season, metric=\"confidence\", min_threshold=0.6)\n",
    "season_rules = season_rules.sort_values('lift', ascending=False)\n",
    "\n",
    "print(f\"\\nSeason-based association rules (min_confidence=0.6):\")\n",
    "print(f\"Number of rules: {len(season_rules)}\")\n",
    "\n",
    "if len(season_rules) > 0:\n",
    "    display(season_rules.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed analysis: Compare associations between different seasons\n",
    "# Separate transactions by season\n",
    "season1_data = df[df['Sesn'] == 1]\n",
    "season2_data = df[df['Sesn'] == 2]\n",
    "\n",
    "def analyze_season_associations(season_data, season_name):\n",
    "    \"\"\"Analyze association rules for a specific season\"\"\"\n",
    "    season_data = season_data.copy()\n",
    "    season_data['context'] = season_data['locn'].astype(str) + '_' + season_data['block'].astype(str)\n",
    "    context_fert = season_data.groupby('context')['ferT'].apply(list).reset_index()\n",
    "    \n",
    "    transactions = context_fert['ferT'].tolist()\n",
    "    \n",
    "    if len(transactions) > 0:\n",
    "        te = TransactionEncoder()\n",
    "        te_ary = te.fit(transactions).transform(transactions)\n",
    "        transactions_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "        \n",
    "        # Generate frequent itemsets\n",
    "        frequent_itemsets = apriori(transactions_df, min_support=0.2, use_colnames=True)\n",
    "        \n",
    "        if len(frequent_itemsets) > 0:\n",
    "            # Generate association rules\n",
    "            rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "            rules = rules.sort_values('confidence', ascending=False)\n",
    "            \n",
    "            print(f\"\\n=== {season_name} Association Rules ===\")\n",
    "            print(f\"Number of rules: {len(rules)}\")\n",
    "            \n",
    "            if len(rules) > 0:\n",
    "                # Add season information to rules\n",
    "                rules['season'] = season_name\n",
    "                display(rules.head(10))\n",
    "                \n",
    "                return rules\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Analyze each season separately\n",
    "season1_rules = analyze_season_associations(season1_data, \"Season 1\")\n",
    "season2_rules = analyze_season_associations(season2_data, \"Season 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6642bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the association rules\n",
    "def plot_association_rules(rules, title):\n",
    "    \"\"\"Plot association rules metrics\"\"\"\n",
    "    if len(rules) == 0:\n",
    "        print(f\"No rules to plot for {title}\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle(f'Association Rules Analysis - {title}', fontsize=16)\n",
    "    \n",
    "    # Support vs Confidence\n",
    "    axes[0, 0].scatter(rules['support'], rules['confidence'], alpha=0.5)\n",
    "    axes[0, 0].set_xlabel('Support')\n",
    "    axes[0, 0].set_ylabel('Confidence')\n",
    "    axes[0, 0].set_title('Support vs Confidence')\n",
    "    \n",
    "    # Lift vs Confidence\n",
    "    axes[0, 1].scatter(rules['lift'], rules['confidence'], alpha=0.5)\n",
    "    axes[0, 1].set_xlabel('Lift')\n",
    "    axes[0, 1].set_ylabel('Confidence')\n",
    "    axes[0, 1].set_title('Lift vs Confidence')\n",
    "    \n",
    "    # Support distribution\n",
    "    axes[1, 0].hist(rules['support'], bins=20, alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Support')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Support Distribution')\n",
    "    \n",
    "    # Lift distribution\n",
    "    axes[1, 1].hist(rules['lift'], bins=20, alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Lift')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Lift Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot rules for overall analysis\n",
    "if len(rules) > 0:\n",
    "    plot_association_rules(rules, \"Overall Analysis\")\n",
    "\n",
    "# Plot rules for season-based analysis if available\n",
    "all_season_rules = pd.concat([season1_rules, season2_rules], ignore_index=True)\n",
    "if len(all_season_rules) > 0:\n",
    "    plot_association_rules(all_season_rules, \"Season-wise Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4eedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis: Compare fertilizer associations between locations\n",
    "def analyze_location_associations(location_data, location_name):\n",
    "    \"\"\"Analyze association rules for a specific location\"\"\"\n",
    "    location_data = location_data.copy()\n",
    "    location_data['context'] = location_data['Sesn'].astype(str) + '_' + location_data['block'].astype(str)\n",
    "    context_fert = location_data.groupby('context')['ferT'].apply(list).reset_index()\n",
    "    \n",
    "    transactions = context_fert['ferT'].tolist()\n",
    "    \n",
    "    if len(transactions) > 0:\n",
    "        te = TransactionEncoder()\n",
    "        te_ary = te.fit(transactions).transform(transactions)\n",
    "        transactions_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "        \n",
    "        # Generate frequent itemsets\n",
    "        frequent_itemsets = apriori(transactions_df, min_support=0.2, use_colnames=True)\n",
    "        \n",
    "        if len(frequent_itemsets) > 0:\n",
    "            # Generate association rules\n",
    "            rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "            rules = rules.sort_values('confidence', ascending=False)\n",
    "            \n",
    "            print(f\"\\n=== {location_name} Association Rules ===\")\n",
    "            print(f\"Number of rules: {len(rules)}\")\n",
    "            \n",
    "            if len(rules) > 0:\n",
    "                rules['location'] = location_name\n",
    "                display(rules.head(10))\n",
    "                return rules\n",
    "    return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each location separately\n",
    "location1_data = df[df['locn'] == 1]  # Soroti\n",
    "location2_data = df[df['locn'] == 2]  # Mukono\n",
    "\n",
    "location1_rules = analyze_location_associations(location1_data, \"Soroti (Location 1)\")\n",
    "location2_rules = analyze_location_associations(location2_data, \"Mukono (Location 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and insights\n",
    "print(\"=== ASSOCIATION RULE MINING SUMMARY ===\")\n",
    "print(f\"Total transactions analyzed: {len(transactions)}\")\n",
    "print(f\"Unique fertilizers: {df['ferT'].unique().tolist()}\")\n",
    "print(f\"Seasons covered: {df['Sesn'].unique().tolist()}\")\n",
    "print(f\"Locations covered: {df['locn'].unique().tolist()}\")\n",
    "\n",
    "print(f\"\\nOverall frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "print(f\"Overall association rules generated: {len(rules)}\")\n",
    "\n",
    "if len(rules) > 0:\n",
    "    print(f\"\\nStrongest association (highest confidence):\")\n",
    "    best_rule = rules.iloc[0]\n",
    "    print(f\"Rule: {list(best_rule['antecedents'])} -> {list(best_rule['consequents'])}\")\n",
    "    print(f\"Confidence: {best_rule['confidence']:.3f}, Support: {best_rule['support']:.3f}, Lift: {best_rule['lift']:.3f}\")\n",
    "\n",
    "print(f\"\\nSeason 1 rules: {len(season1_rules)}\")\n",
    "print(f\"Season 2 rules: {len(season2_rules)}\")\n",
    "print(f\"Soroti location rules: {len(location1_rules)}\")\n",
    "print(f\"Mukono location rules: {len(location2_rules)}\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n=== KEY INSIGHTS ===\")\n",
    "if len(rules) > 0:\n",
    "    high_confidence_rules = rules[rules['confidence'] > 0.7]\n",
    "    if len(high_confidence_rules) > 0:\n",
    "        print(\"High-confidence associations found:\")\n",
    "        for _, rule in high_confidence_rules.iterrows():\n",
    "            print(f\"  {list(rule['antecedents'])} -> {list(rule['consequents'])} (conf: {rule['confidence']:.2f})\")\n",
    "    \n",
    "    high_lift_rules = rules[rules['lift'] > 1.5]\n",
    "    if len(high_lift_rules) > 0:\n",
    "        print(\"\\nHigh-lift associations (most meaningful):\")\n",
    "        for _, rule in high_lift_rules.iterrows():\n",
    "            print(f\"  {list(rule['antecedents'])} -> {list(rule['consequents'])} (lift: {rule['lift']:.2f})\")\n",
    "else:\n",
    "    print(\"No strong associations found with current parameters. Try adjusting min_support or min_confidence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED ASSOCIATION RULE MINING FOR FERTILIZER PATTERNS ACROSS SEASONS\n",
    "# Let's analyze the data structure more carefully first\n",
    "\n",
    "print(\"=== DATA STRUCTURE ANALYSIS ===\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Unique combinations:\")\n",
    "print(f\"  - Seasons: {sorted(df['Sesn'].unique())}\")\n",
    "print(f\"  - Locations: {sorted(df['locn'].unique())}\")\n",
    "print(f\"  - Blocks: {sorted(df['block'].unique())}\")\n",
    "print(f\"  - Fertilizers: {sorted(df['ferT'].unique())}\")\n",
    "\n",
    "# Check how fertilizers are distributed across seasons\n",
    "print(f\"\\n=== FERTILIZER DISTRIBUTION BY SEASON ===\")\n",
    "for season in sorted(df['Sesn'].unique()):\n",
    "    season_data = df[df['Sesn'] == season]\n",
    "    print(f\"Season {season}:\")\n",
    "    print(f\"  - Records: {len(season_data)}\")\n",
    "    print(f\"  - Unique fertilizers: {sorted(season_data['ferT'].unique())}\")\n",
    "    print(f\"  - Fertilizer frequency:\")\n",
    "    fert_counts = season_data['ferT'].value_counts()\n",
    "    for fert, count in fert_counts.items():\n",
    "        print(f\"    {fert}: {count} times\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED APPROACH: Create transactions based on individual experimental plots\n",
    "# Each plot represents a transaction where the items are the fertilizers used\n",
    "\n",
    "print(\"=== CREATING PROPER TRANSACTION FORMAT ===\")\n",
    "\n",
    "# Method 1: Each experimental plot is a transaction\n",
    "# Group by season, location, block, and replication to get individual plots\n",
    "df['plot_id'] = df['Sesn'].astype(str) + '_' + df['locn'].astype(str) + '_' + df['block'].astype(str) + '_' + df['rep'].astype(str)\n",
    "\n",
    "# Each plot should have only one fertilizer type, so we need to check this\n",
    "print(\"Checking fertilizer distribution per plot:\")\n",
    "plot_fert_check = df.groupby('plot_id')['ferT'].nunique()\n",
    "print(f\"Plots with multiple fertilizers: {(plot_fert_check > 1).sum()}\")\n",
    "print(f\"Total plots: {len(plot_fert_check)}\")\n",
    "\n",
    "if (plot_fert_check > 1).sum() == 0:\n",
    "    print(\"✓ Each plot has only one fertilizer type - good for association rule mining\")\n",
    "else:\n",
    "    print(\"⚠ Some plots have multiple fertilizers - need different approach\")\n",
    "\n",
    "# Create transactions where each plot is a transaction and fertilizer is an item\n",
    "# But we need to think about what we're trying to find associations for...\n",
    "\n",
    "# Let's try a different approach: Group by experimental design factors\n",
    "# and see what combinations of fertilizers appear together in similar contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE APPROACH: Look for associations between fertilizers across seasons\n",
    "# We'll create transactions based on experimental blocks where multiple fertilizers are tested\n",
    "\n",
    "print(\"=== ALTERNATIVE APPROACH: BLOCK-BASED TRANSACTIONS ===\")\n",
    "\n",
    "# Create transactions at the block level within each season-location combination\n",
    "# Each block contains multiple fertilizer treatments\n",
    "\n",
    "df['season_location'] = df['Sesn'].astype(str) + '_' + df['locn'].astype(str)\n",
    "\n",
    "# Group by season-location-block and collect all fertilizers used in that block\n",
    "block_fertilizers = df.groupby(['season_location', 'block'])['ferT'].apply(list).reset_index()\n",
    "block_fertilizers.columns = ['season_location', 'block', 'fertilizers']\n",
    "\n",
    "print(\"Block-level fertilizer combinations:\")\n",
    "print(block_fertilizers)\n",
    "\n",
    "# Convert to transaction format\n",
    "transactions = block_fertilizers['fertilizers'].tolist()\n",
    "\n",
    "print(f\"\\nNumber of transactions: {len(transactions)}\")\n",
    "print(\"Sample transactions:\")\n",
    "for i, trans in enumerate(transactions[:5]):\n",
    "    print(f\"  Transaction {i+1}: {trans}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f772e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY APRIORI ALGORITHM WITH PROPER PARAMETERS\n",
    "\n",
    "# Convert transactions to binary matrix format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "transactions_df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(f\"Transaction matrix shape: {transactions_df.shape}\")\n",
    "print(\"\\nTransaction matrix:\")\n",
    "print(transactions_df)\n",
    "\n",
    "# Calculate appropriate minimum support\n",
    "# With 6 transactions and 5 unique fertilizers, let's use a reasonable threshold\n",
    "min_support = 0.5  # At least 3 out of 6 transactions should contain the itemset\n",
    "\n",
    "print(f\"\\n=== APRIORI ALGORITHM ===\")\n",
    "print(f\"Minimum support: {min_support}\")\n",
    "\n",
    "# Generate frequent itemsets\n",
    "frequent_itemsets = apriori(transactions_df, min_support=min_support, use_colnames=True)\n",
    "frequent_itemsets = frequent_itemsets.sort_values('support', ascending=False)\n",
    "\n",
    "print(f\"\\nFrequent itemsets found: {len(frequent_itemsets)}\")\n",
    "print(\"\\nFrequent itemsets:\")\n",
    "display(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE ASSOCIATION RULES\n",
    "\n",
    "if len(frequent_itemsets) > 1:  # Need at least 2 itemsets to generate rules\n",
    "    # Generate association rules with different metrics\n",
    "    print(\"=== ASSOCIATION RULES GENERATION ===\")\n",
    "    \n",
    "    # Try different confidence thresholds\n",
    "    confidence_thresholds = [0.5, 0.6, 0.7, 0.8]\n",
    "    \n",
    "    for conf_thresh in confidence_thresholds:\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=conf_thresh)\n",
    "        \n",
    "        if len(rules) > 0:\n",
    "            rules = rules.sort_values('confidence', ascending=False)\n",
    "            print(f\"\\n--- Rules with confidence >= {conf_thresh} ---\")\n",
    "            print(f\"Number of rules: {len(rules)}\")\n",
    "            \n",
    "            # Display top 5 rules\n",
    "            top_rules = rules.head(5)\n",
    "            for idx, rule in top_rules.iterrows():\n",
    "                antecedents = list(rule['antecedents'])\n",
    "                consequents = list(rule['consequents'])\n",
    "                print(f\"  {antecedents} -> {consequents}\")\n",
    "                print(f\"    Support: {rule['support']:.3f}, Confidence: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(f\"\\nNo rules found with confidence >= {conf_thresh}\")\n",
    "    \n",
    "    # Focus on rules with lift > 1 (positive association)\n",
    "    if len(frequent_itemsets) > 1:\n",
    "        rules_lift = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "        \n",
    "        if len(rules_lift) > 0:\n",
    "            rules_lift = rules_lift.sort_values('lift', ascending=False)\n",
    "            print(f\"\\n=== RULES WITH POSITIVE LIFT (Lift > 1.0) ===\")\n",
    "            print(f\"Number of rules: {len(rules_lift)}\")\n",
    "            \n",
    "            # Display all rules with positive lift\n",
    "            for idx, rule in rules_lift.iterrows():\n",
    "                antecedents = list(rule['antecedents'])\n",
    "                consequents = list(rule['consequents'])\n",
    "                print(f\"  {antecedents} -> {consequents}\")\n",
    "                print(f\"    Support: {rule['support']:.3f}, Confidence: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"\\nNo rules found with lift > 1.0\")\n",
    "            \n",
    "else:\n",
    "    print(\"Not enough frequent itemsets to generate association rules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION OF RESULTS\n",
    "\n",
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Association Rule Mining Analysis: Fertilizer Patterns Across Seasons', fontsize=16)\n",
    "\n",
    "# 1. Support distribution of frequent itemsets\n",
    "axes[0, 0].bar(range(len(frequent_itemsets)), frequent_itemsets['support'])\n",
    "axes[0, 0].set_xlabel('Itemset Index')\n",
    "axes[0, 0].set_ylabel('Support')\n",
    "axes[0, 0].set_title('Support Distribution of Frequent Itemsets')\n",
    "axes[0, 0].set_xticks(range(len(frequent_itemsets)))\n",
    "axes[0, 0].set_xticklabels([f\"{i+1}\" for i in range(len(frequent_itemsets))])\n",
    "\n",
    "# 2. Itemset size distribution\n",
    "itemset_sizes = frequent_itemsets['itemsets'].apply(len)\n",
    "size_counts = itemset_sizes.value_counts().sort_index()\n",
    "axes[0, 1].bar(size_counts.index, size_counts.values)\n",
    "axes[0, 1].set_xlabel('Itemset Size')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].set_title('Distribution of Itemset Sizes')\n",
    "axes[0, 1].set_xticks(size_counts.index)\n",
    "\n",
    "# 3. Fertilizer frequency in transactions\n",
    "fert_counts = transactions_df.sum().sort_values(ascending=False)\n",
    "axes[1, 0].bar(fert_counts.index, fert_counts.values)\n",
    "axes[1, 0].set_xlabel('Fertilizers')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Fertilizer Frequency Across All Transactions')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Transaction composition heatmap\n",
    "axes[1, 1].imshow(transactions_df.astype(int), cmap='Blues', aspect='auto')\n",
    "axes[1, 1].set_xlabel('Fertilizers')\n",
    "axes[1, 1].set_ylabel('Transactions')\n",
    "axes[1, 1].set_title('Transaction-Fertilizer Matrix')\n",
    "axes[1, 1].set_xticks(range(len(transactions_df.columns)))\n",
    "axes[1, 1].set_xticklabels(transactions_df.columns, rotation=45)\n",
    "axes[1, 1].set_yticks(range(len(transactions_df)))\n",
    "axes[1, 1].set_yticklabels([f\"T{i+1}\" for i in range(len(transactions_df))])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK VISUALIZATION OF ASSOCIATION RULES (if any exist)\n",
    "\n",
    "if len(frequent_itemsets) > 1:\n",
    "    # Try to get some rules for visualization\n",
    "    try:\n",
    "        rules_for_viz = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)\n",
    "        \n",
    "        if len(rules_for_viz) > 0:\n",
    "            # Create network graph\n",
    "            import networkx as nx\n",
    "            \n",
    "            G = nx.DiGraph()\n",
    "            \n",
    "            # Add nodes for all fertilizers\n",
    "            for fert in transactions_df.columns:\n",
    "                G.add_node(fert)\n",
    "            \n",
    "            # Add edges based on rules\n",
    "            for _, rule in rules_for_viz.iterrows():\n",
    "                for antecedent in rule['antecedents']:\n",
    "                    for consequent in rule['consequents']:\n",
    "                        if antecedent != consequent:  # Avoid self-loops\n",
    "                            G.add_edge(antecedent, consequent, \n",
    "                                      weight=rule['lift'], \n",
    "                                      confidence=rule['confidence'],\n",
    "                                      support=rule['support'])\n",
    "            \n",
    "            # Create the network visualization\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            pos = nx.spring_layout(G, k=1, seed=42)\n",
    "            \n",
    "            # Draw nodes\n",
    "            nx.draw_networkx_nodes(G, pos, node_size=1500, \n",
    "                                 node_color='lightblue', alpha=0.8)\n",
    "            \n",
    "            # Draw edges with thickness based on lift\n",
    "            edges = G.edges(data=True)\n",
    "            if edges:\n",
    "                weights = [d['weight'] for (u, v, d) in edges]\n",
    "                max_weight = max(weights) if weights else 1\n",
    "                edge_widths = [w/max_weight * 5 for w in weights]\n",
    "                \n",
    "                nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=20,\n",
    "                                     width=edge_widths, alpha=0.6, edge_color='gray')\n",
    "            \n",
    "            # Draw labels\n",
    "            nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "            \n",
    "            # Add edge labels for top rules\n",
    "            if edges:\n",
    "                top_edges = sorted(edges, key=lambda x: x[2]['lift'], reverse=True)[:5]\n",
    "                edge_labels = {}\n",
    "                for u, v, d in top_edges:\n",
    "                    edge_labels[(u, v)] = f\"L:{d['lift']:.2f}\"\n",
    "                \n",
    "                nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=8)\n",
    "            \n",
    "            plt.title('Association Rules Network\\n(Edge thickness = Lift, Labels show top Lift values)', \n",
    "                     fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"Network visualization created with {len(G.nodes())} nodes and {len(G.edges())} edges\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No rules found for network visualization\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not create network visualization: {e}\")\n",
    "else:\n",
    "    print(\"Not enough frequent itemsets for network visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE ANALYSIS AND INTERPRETATION\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ASSOCIATION RULE MINING ANALYSIS: FERTILIZER PATTERNS ACROSS SEASONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"   • Total experimental records: {len(df)}\")\n",
    "print(f\"   • Seasons analyzed: {sorted(df['Sesn'].unique())}\")\n",
    "print(f\"   • Locations: {sorted(df['locn'].unique())} (1=Soroti, 2=Mukono)\")\n",
    "print(f\"   • Fertilizers: {sorted(df['ferT'].unique())}\")\n",
    "print(f\"   • Transactions created: {len(transactions)}\")\n",
    "\n",
    "print(f\"\\n🔍 METHODOLOGY:\")\n",
    "print(f\"   • Transaction format: Block-level fertilizer combinations\")\n",
    "print(f\"   • Minimum support threshold: {min_support}\")\n",
    "print(f\"   • Algorithm: Apriori\")\n",
    "print(f\"   • Each transaction represents fertilizers tested in the same experimental block\")\n",
    "\n",
    "print(f\"\\n📈 FREQUENT ITEMSETS RESULTS:\")\n",
    "print(f\"   • Total frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "\n",
    "if len(frequent_itemsets) > 0:\n",
    "    print(f\"   • Itemset sizes: {sorted(frequent_itemsets['itemsets'].apply(len).unique())}\")\n",
    "    print(f\"   • Support range: {frequent_itemsets['support'].min():.3f} - {frequent_itemsets['support'].max():.3f}\")\n",
    "    \n",
    "    # Show most frequent itemsets\n",
    "    print(f\"\\n   Top frequent itemsets:\")\n",
    "    for idx, row in frequent_itemsets.head(5).iterrows():\n",
    "        itemset_str = ', '.join(list(row['itemsets']))\n",
    "        print(f\"     {itemset_str} (Support: {row['support']:.3f})\")\n",
    "\n",
    "print(f\"\\n🎯 ASSOCIATION RULES ANALYSIS:\")\n",
    "\n",
    "if len(frequent_itemsets) > 1:\n",
    "    # Try to get rules with different thresholds\n",
    "    rules_summary = {}\n",
    "    \n",
    "    for conf in [0.5, 0.6, 0.7, 0.8]:\n",
    "        try:\n",
    "            rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=conf)\n",
    "            rules_summary[conf] = len(rules)\n",
    "        except:\n",
    "            rules_summary[conf] = 0\n",
    "    \n",
    "    print(f\"   Rules found with different confidence thresholds:\")\n",
    "    for conf, count in rules_summary.items():\n",
    "        print(f\"     Confidence ≥ {conf}: {count} rules\")\n",
    "    \n",
    "    # Check for meaningful associations (lift > 1)\n",
    "    try:\n",
    "        meaningful_rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.1)\n",
    "        print(f\"   Rules with lift > 1.1: {len(meaningful_rules)}\")\n",
    "        \n",
    "        if len(meaningful_rules) > 0:\n",
    "            print(f\"\\n   🏆 MOST MEANINGFUL ASSOCIATIONS:\")\n",
    "            top_rules = meaningful_rules.nlargest(3, 'lift')\n",
    "            for idx, rule in top_rules.iterrows():\n",
    "                antecedents = ', '.join(list(rule['antecedents']))\n",
    "                consequents = ', '.join(list(rule['consequents']))\n",
    "                print(f\"     {antecedents} → {consequents}\")\n",
    "                print(f\"       Support: {rule['support']:.3f}, Confidence: {rule['confidence']:.3f}, Lift: {rule['lift']:.3f}\")\n",
    "                print()\n",
    "    except:\n",
    "        print(f\"   No meaningful associations found (lift > 1.1)\")\n",
    "else:\n",
    "    print(f\"   Cannot generate association rules - insufficient frequent itemsets\")\n",
    "\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "\n",
    "# Analyze fertilizer co-occurrence patterns\n",
    "fert_pairs = []\n",
    "for trans in transactions:\n",
    "    if len(trans) > 1:\n",
    "        for i in range(len(trans)):\n",
    "            for j in range(i+1, len(trans)):\n",
    "                fert_pairs.append(tuple(sorted([trans[i], trans[j]])))\n",
    "\n",
    "from collections import Counter\n",
    "pair_counts = Counter(fert_pairs)\n",
    "\n",
    "if pair_counts:\n",
    "    print(f\"   Most common fertilizer pairs in the same experimental blocks:\")\n",
    "    for pair, count in pair_counts.most_common(5):\n",
    "        print(f\"     {pair[0]} & {pair[1]}: {count} times\")\n",
    "\n",
    "# Season-specific analysis\n",
    "print(f\"\\n   Season-specific fertilizer usage:\")\n",
    "for season in sorted(df['Sesn'].unique()):\n",
    "    season_data = df[df['Sesn'] == season]\n",
    "    season_ferts = season_data['ferT'].value_counts()\n",
    "    print(f\"     Season {season}: {dict(season_ferts)}\")\n",
    "\n",
    "print(f\"\\n📋 CONCLUSIONS:\")\n",
    "print(f\"   1. The experimental design ensures all fertilizers are tested in each block\")\n",
    "print(f\"   2. This creates a systematic co-occurrence pattern rather than natural associations\")\n",
    "print(f\"   3. True fertilizer associations would require different experimental design\")\n",
    "print(f\"   4. The high support values (all fertilizers appear together) indicate planned co-occurrence\")\n",
    "print(f\"   5. For meaningful association mining, we would need:\")\n",
    "print(f\"      • Farmer choice data (which fertilizers farmers actually use together)\")\n",
    "print(f\"      • Market basket data (which fertilizers are purchased together)\")\n",
    "print(f\"      • Yield-based associations (which fertilizer combinations lead to better yields)\")\n",
    "\n",
    "print(f\"\\n🔬 RECOMMENDATIONS FOR FUTURE ANALYSIS:\")\n",
    "print(f\"   • Analyze fertilizer effectiveness combinations (yield-based associations)\")\n",
    "print(f\"   • Study seasonal fertilizer preferences and patterns\")\n",
    "print(f\"   • Compare fertilizer combinations across different locations\")\n",
    "print(f\"   • Use yield data to find effective fertilizer synergies\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
